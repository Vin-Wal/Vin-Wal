#Question 5
# We could use either of the above to begin creating an X matrix that would (potentially) allow us to predict better than just the numeric columns we have been using thus far.


#Create a copy of the dataframe
cat_df_copy = cat_df.copy()
#Pull a list of the column names of the categorical variables
cat_cols_lst = cat_df.columns

def create_dummy_df(df, cat_cols, dummy_na):
    '''
    INPUT:
    df - pandas dataframe with categorical variables you want to dummy
    cat_cols - list of strings that are associated with names of the categorical columns
    dummy_na - Bool holding whether you want to dummy NA vals of categorical columns or not
    
    OUTPUT:
    df - a new dataframe that has the following characteristics:
            1. contains all columns that were not specified as categorical
            2. removes all the original columns in cat_cols
            3. dummy columns for each of the categorical columns in cat_cols
            4. if dummy_na is True - it also contains dummy columns for the NaN values
            5. Use a prefix of the column name with an underscore (_) for separating 
    '''
    
    df = pd.get_dummies(data = df,columns = cat_cols,dummy_na = dummy_na,prefix_sep ='_',drop_first = True )

    return df
    
    #Question 6
    #Use the document string below to complete the function. Then test your function against the solution.
    def clean_fit_linear_mod(df, response_col, cat_cols, dummy_na, test_size=.3, rand_state=42):
    '''
    INPUT:
    df - a dataframe holding all the variables of interest
    response_col - a string holding the name of the column 
    cat_cols - list of strings that are associated with names of the categorical columns
    dummy_na - Bool holding whether you want to dummy NA vals of categorical columns or not
    test_size - a float between [0,1] about what proportion of data should be in the test dataset
    rand_state - an int that is provided as the random state for splitting the data into training and test 
    
    OUTPUT:
    test_score - float - r2 score on the test data
    train_score - float - r2 score on the test data
    lm_model - model object from sklearn
    X_train, X_test, y_train, y_test - output from sklearn train test split used for optimal model
    
    Your function should:
    1. Drop the rows with missing response values
    2. Drop columns with NaN for all the values
    3. Use create_dummy_df to dummy categorical columns
    4. Fill the mean of the column for any missing values 
    5. Split your data into an X matrix and a response vector y
    6. Create training and test sets of data
    7. Instantiate a LinearRegression model with normalized data
    8. Fit your model to the training data
    9. Predict the response for the training data and the test data
    10. Obtain an rsquared value for both the training and test data
    '''
    
    df = df.dropna(subset = [response_col],axis=0)
    df = df.dropna(how = 'all',axis=1)
    
    
    continous_cols = [col for col in df.columns if df[col].dtype in ['float64','int64']]
    df = create_dummy_df(df,cat_cols,dummy_na = dummy_na)
    
    fill_mean = lambda col : col.fillna(col.mean())
    df = df.apply(fill_mean,axis=0)
    print(df)
    
#     for col in continous_cols:
#         df[col].apply(fill_mean)
    
    X = df.drop(columns = [response_col])
    Y = df['Salary']
    
    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = test_size, random_state = rand_state)
    
    lm_model = LinearRegression(normalize = True)
    lm_model.fit(X_train,y_train)
    
    y_train_pred = lm_model.predict(X_train)
    y_test_pred = lm_model.predict(X_test)
    
    train_score = r2_score(y_train,y_train_pred)
    test_score = r2_score(y_test,y_test_pred)
    
    
    return test_score, train_score, lm_model, X_train, X_test, y_train, y_test


#Test your function with the above dataset
test_score, train_score, lm_model, X_train, X_test, y_train, y_test = clean_fit_linear_mod(df_new, 'Salary', cat_cols_lst, dummy_na=False)
